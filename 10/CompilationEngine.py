import JackTokenizer
import JackAnalyzer
"""
Effects the actual compilation output. Gets its input from a JackTokenizer and
emits its parsed structure into an output file/stream. The output is generated by a
series of compilexxx() routines, one for every syntactic element xxx of the Jack grammar.
The contract between these routines is that each compilexxx() routine should read the
syntactic construct xxx from the input, advance() the tokenizer exactly beyond xxx,
and output the parsing of xxx. Thus, compilexxx()may only be called if
indeed xxx is the next syntactic element of the input.
"""


# global dictionary and lists
keywords_mapping = {'class': 'class', 'field': 'classVarDec', 'static': 'classVarDec',
                    'constructor': 'subroutineDec', 'function': 'subroutineDec',
                    'method': 'subroutineDec', 'var': 'varDec', 'let': 'letStatement',
                    'do': 'doStatement', 'if': 'ifStatement', 'while': 'whileStatement',
                    'return': 'returnStatement'}
statements = ['let', 'if', 'while', 'do', 'return']
op = ['+', '-', '*', '/', '&', '"', '|', '<', '>', '=']

# constants
TOKEN_NAME = 0
TOKEN_TYPE = 1


class CompilationEngine:
    """
    Effects the actual compilation output. Gets its input from a JackTokenizer and emits
    its parsed structure into an output file/stream.
    The output is generated by a series of compilexxx() routines,
    one for every syntactic element xxx of the Jack grammar.
    """
    def __init__(self, folder_path, jack_file_name):
        """
        Constructor
        """
        self.tokenizer = JackTokenizer.JackTokenizer(folder_path, jack_file_name)
        self.xml_lines = []
        self.output_file_path = folder_path + jack_file_name.replace\
            (JackAnalyzer.SOURCE_FILE_EXTENSION, JackAnalyzer.DEST_FILE_EXTENSION)

        # compile class will drive the compile xxx methods
        self.compile_class()

        # prepare the file for writing
        self.xml_file = open(self.output_file_path, 'w')

        # write output xml file from our xml_lines list
        self.write_xml_file()

    def append_next_xml_line(self):
        """
        This method create xml entry from the next token by using tokenizer.advance()
        """
        value, element_name = self.tokenizer.advance()
        if value in op:
            value = self.change_symbol_for_xml_val(value)
        xml_row = self.create_xml_entry(element_name, value)
        self.xml_lines.append(xml_row)

    def append_xml_lines(self, num_of_lines):
        """
        Call to append_next_xml_line method which creates xml row, several times
        :param num_of_lines: number of lines to create
        """
        for i in range(num_of_lines):
            self.append_next_xml_line()

    def compile_class(self):
        """
        Compiles a complete class.
        """
        self.xml_lines.append("<class>")
        # write <keyword> class </keyword>
        # <identifier> name of class </identifier>
        # <symbol>{</symbol>
        self.append_xml_lines(3)
        # compile the variable declarations part of the class if exist
        self.compile_var_dec(True)
        # class can contain constructor and one or more methods|functions (subroutines)
        # here we will compile all of the subroutines
        while self.tokenizer.peek_next_token()[TOKEN_NAME] in keywords_mapping.keys() \
                and keywords_mapping[self.tokenizer.peek_next_token()[TOKEN_NAME]] == \
                'subroutineDec':
            self.compile_subroutine()
        # write <symbol>}</symbol>
        self.append_next_xml_line()
        self.xml_lines.append("</class>")

    def compile_var_dec(self, is_class_var_dec):
        """
        :param is_class_var_dec: boolean, true if we compile class var dec, otherwise,
        we compile var inside subroutine of the class
        """
        if is_class_var_dec:
            var_dec_str = 'classVarDec'
        else:
            var_dec_str = 'varDec'

        while self.tokenizer.peek_next_token()[TOKEN_NAME] in keywords_mapping.keys() \
                and keywords_mapping[self.tokenizer.peek_next_token()[TOKEN_NAME]] \
                == var_dec_str:
            self.xml_lines.append('<' + var_dec_str + '>')
            # write <keyword> field or static </keyword>
            # <identifier> variable type </identifier>
            # <identifier> variable name </identifier>
            self.append_xml_lines(3)
            # compile line of multi variable declarations (Separated by ',')
            while self.tokenizer.peek_next_token()[TOKEN_NAME] == JackTokenizer.COMMA:
                # write <symbol>,</symbol>
                # <identifier> new var name </identifier>
                self.append_xml_lines(2)
            # write <symbol>;</symbol>
            self.append_next_xml_line()
            self.xml_lines.append('</' + var_dec_str + '>')

    def compile_subroutine(self):
        """
        Compiles a complete method, function, or constructor.
        """
        self.xml_lines.append('<subroutineDec>')
        # write <keyword>type of the subroutine</keyword>
        # <identifier>return type of the subroutine</identifier>
        # <identifier>name of subroutine</identifier>
        # <symbol>(</symbol>
        self.append_xml_lines(4)
        # compile the parameters of the subroutine
        self.compile_parameter_list()
        # write <symbol>)</symbol>
        self.append_next_xml_line()
        self.xml_lines.append('<subroutineBody>')
        # write <symbol>{</symbol>
        self.append_next_xml_line()
        # compile the variable declarations part of the subroutine if exist
        self.compile_var_dec(False)
        # compile the subroutine body
        self.compile_statements()
        # write <symbol>}</symbol>
        self.append_next_xml_line()
        self.xml_lines.append('</subroutineBody>')
        self.xml_lines.append('</subroutineDec>')

    def compile_parameter_list(self):
        """
        Compiles a (possibly empty) parameter list, not including the enclosing “()”.
        """
        self.xml_lines.append('<parameterList>')
        while not self.tokenizer.peek_next_token()[TOKEN_NAME] == \
                JackTokenizer.END_PARENTHESES:
            self.append_next_xml_line()
        self.xml_lines.append('</parameterList>')

    def compile_statements(self):
        """
        Compiles a sequence of statements, not including the enclosing “{}”.
        """
        self.xml_lines.append('<statements>')
        # now, it can be one of the following:
        # letStatement | ifStatement | whileStatement | doStatement | returnStatement
        token_name = self.tokenizer.peek_next_token()[TOKEN_NAME]
        while token_name in statements:
            if token_name == 'let':
                self.compile_let()
            elif token_name == 'if':
                self.compile_if()
            elif token_name == 'while':
                self.compile_while()
            elif token_name == 'do':
                self.compile_do()
            elif token_name == 'return':
                self.compile_return()
            # next statement
            token_name = self.tokenizer.peek_next_token()[TOKEN_NAME]

        self.xml_lines.append('</statements>')

    def compile_do(self):
        """
        Compiles a do statement.
        """
        self.xml_lines.append('<doStatement>')
        # write <keyword> do </keyword>
        # <identifier> name of do </identifier>
        self.append_xml_lines(2)
        if self.tokenizer.peek_next_token()[TOKEN_NAME] == JackTokenizer.DOT:
            # write <symbol> . </symbol>
            # <identifier> name of func </identifier>
            self.append_xml_lines(2)

        # write <symbol> ( </symbol>
        self.append_next_xml_line()
        self.compile_expression_list()

        # write <symbol> ) </symbol>
        # <symbol> ; </symbol>
        self.append_xml_lines(2)
        self.xml_lines.append('</doStatement>')

    def compile_let(self):
        """
        Compiles a let statement.
        """
        self.xml_lines.append('<letStatement>')
        # write <keyword> let </keyword>
        # <identifier> name of assignee </identifier>
        self.append_xml_lines(2)
        if self.tokenizer.peek_next_token()[TOKEN_NAME] == JackTokenizer.START_BRACKETS:
            # write  <symbol> [ </symbol>
            self.append_next_xml_line()
            self.compile_expression()
            # write  <symbol> ] </symbol>
            self.append_next_xml_line()
        # write  <symbol> = </symbol>
        self.append_next_xml_line()
        self.compile_expression()
        # write  <symbol> ; </symbol>
        self.append_next_xml_line()
        self.xml_lines.append('</letStatement>')

    def compile_while(self):
        """
        Compiles a while statement.
        """
        self.xml_lines.append('<whileStatement>')
        # write <keyword> while </keyword>
        # <symbol> ( </symbol>
        self.append_xml_lines(2)
        self.compile_expression()
        # write <symbol> ) </symbol>
        # <symbol> { </symbol>
        self.append_xml_lines(2)
        self.compile_statements()
        # write <symbol> } </symbol>
        self.append_next_xml_line()
        self.xml_lines.append('</whileStatement>')

    def compile_return(self):
        """
        Compiles a return statement.
        """
        self.xml_lines.append('<returnStatement>')
        # write <keyword> return </keyword>
        self.append_next_xml_line()

        # it can be return; or return with expression and then ;
        if not self.tokenizer.peek_next_token()[TOKEN_NAME] == JackTokenizer.SEMICOLON:
            self.compile_expression()

        # write <symbol> ; </symbol>
        self.append_next_xml_line()

        self.xml_lines.append('</returnStatement>')

    def compile_if(self):
        """
        Compiles an if statement, possibly with a trailing else clause.
        """
        self.xml_lines.append('<ifStatement>')
        # write <keyword> if </keyword>
        # <symbol> ( </symbol>
        self.append_xml_lines(2)
        self.compile_expression()
        # write  <symbol> ) </symbol>
        # <symbol> { </symbol>
        self.append_xml_lines(2)
        self.compile_statements()
        # write  <symbol> } </symbol>
        self.append_next_xml_line()

        if self.tokenizer.peek_next_token()[TOKEN_NAME] == 'else':
            # write <keyword> else </keyword>
            # <symbol> { </symbol>
            self.append_xml_lines(2)
            self.compile_statements()
            # write  <symbol> } </symbol>
            self.append_next_xml_line()

        self.xml_lines.append('</ifStatement>')

    def compile_expression(self):
        """
        Compiles an expression.
        """
        self.xml_lines.append('<expression>')
        self.compile_term()
        # it can be only a term or a term-operation-term, let's check it
        if self.tokenizer.peek_next_token()[TOKEN_NAME] in op:
            # write <symbol> op </symbol>
            self.append_next_xml_line()
            self.compile_term()
        self.xml_lines.append('</expression>')

    def compile_term(self):
        """
        Compiles a term. This routine is faced with a slight difficulty when trying to
        decide between some of the alternative parsing rules.
        Specifically, if the current token is an identifier, the routine must distinguish
        between a variable, an array entry, and a subroutine call. A single look-ahead
        token, which may be one of “[“, “(“, or “.” suffices to distinguish between
        the three possibilities. Any other token is not part of
        this term and should not be advanced over.
        """
        self.xml_lines.append('<term>')
        if self.tokenizer.peek_next_token()[TOKEN_NAME] in \
                JackTokenizer.keyword_constant or self.tokenizer.peek_next_token() \
            [TOKEN_TYPE] in ['integerConstant', 'stringConstant']:
            self.append_next_xml_line()
        elif self.tokenizer.peek_next_token()[TOKEN_TYPE] == 'identifier':
            # write <identifier> name of the identifier </identifier>
            self.append_next_xml_line()
            # check if single look-ahead token one of “[“, “(“, or “.” to distinguish
            # between variable, array entry and subroutine call
            if self.tokenizer.peek_next_token()[TOKEN_NAME] == JackTokenizer.DOT:
                # write <symbol> . </symbol>
                # <identifier> new </identifier>
                # <symbol> ( </symbol>
                self.append_xml_lines(3)
                self.compile_expression_list()
                # write <symbol> ) </symbol>
                self.append_next_xml_line()
            elif self.tokenizer.peek_next_token()[TOKEN_NAME] == \
                    JackTokenizer.START_PARENTHESES:
                # write <symbol> ( </symbol>
                self.append_next_xml_line()
                self.compile_expression_list()
                # write <symbol> ) </symbol>
                self.append_next_xml_line()
            elif self.tokenizer.peek_next_token()[TOKEN_NAME] == \
                    JackTokenizer.START_BRACKETS:
                # write <symbol> [ </symbol>
                self.append_next_xml_line()
                self.compile_expression()
                # write <symbol> ] </symbol>
                self.append_next_xml_line()
        elif self.tokenizer.peek_next_token()[TOKEN_NAME] == \
                JackTokenizer.START_PARENTHESES:
            # write <symbol> ( </symbol>
            self.append_next_xml_line()
            self.compile_expression()
            # write <symbol> ) </symbol>
            self.append_next_xml_line()
        elif self.tokenizer.peek_next_token()[TOKEN_NAME] in ['-', '~']:
            self.append_next_xml_line()
            self.compile_term()

        self.xml_lines.append('</term>')

    def compile_expression_list(self):
        """
        Compiles a (possibly empty) comma separated list of expressions.
        """
        self.xml_lines.append('<expressionList>')
        if not self.tokenizer.peek_next_token()[TOKEN_NAME] == \
                JackTokenizer.END_PARENTHESES:
            self.compile_expression()
        while self.tokenizer.peek_next_token()[TOKEN_NAME] == JackTokenizer.COMMA:
            # write <symbol> , </symbol>
            self.append_next_xml_line()
            self.compile_expression()
        self.xml_lines.append('</expressionList>')

    def create_xml_entry(self, element_name, value):
        """
        This method is responsible to create xml line
        :param element_name: name of the element
        :param value: value of the element
        :return: line in the format of xml file which is generated from element_name
        and the value of the element
        """
        return "<" + element_name + "> " + value + " </" + element_name + ">"

    def change_symbol_for_xml_val(self, input_symbol_token):
        """
        This method is responsible to replace the tokens < > " and & with
        &lt, &gt, &quot, &amp respectively
        :param input_symbol_token: the input symbol token
        :return token after the replacement
        """
        if input_symbol_token == '<':
            replacement_val = '&lt;'
        elif input_symbol_token == '>':
            replacement_val = '&gt;'
        elif input_symbol_token == '"':
            replacement_val = '&quot;'
        elif input_symbol_token == '&':
            replacement_val = '&amp;'
        else:
            replacement_val = input_symbol_token
        return replacement_val

    def write_xml_file(self):
        """
        Writes the content of xml_lines list into the xml_file output file
        """
        for item in self.xml_lines:
            self.xml_file.write("{}\n".format(item))

    def print_xml_lines(self):
        """
        For the convenience of the programmer, prints the items in xml_lines list
        """
        for line in self.xml_lines:
            print(line)
